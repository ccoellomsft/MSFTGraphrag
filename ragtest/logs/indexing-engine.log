13:59:11,501 graphrag.cli.index INFO Logging enabled at C:\Users\ccoello\Documents\GraphRag\ragtest\logs\indexing-engine.log
13:59:12,265 httpx INFO HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 401 Unauthorized"
14:02:30,851 graphrag.cli.index INFO Logging enabled at C:\Users\ccoello\Documents\GraphRag\ragtest\logs\indexing-engine.log
14:02:32,962 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:02:33,259 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/embeddings "HTTP/1.1 404 Resource Not Found"
14:03:21,270 graphrag.cli.index INFO Logging enabled at C:\Users\ccoello\Documents\GraphRag\ragtest\logs\indexing-engine.log
14:03:22,371 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:22,753 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:03:22,756 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:03:22,757 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "encoding_model": "o200k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2025-01-01-preview",
            "deployment_name": "gpt-4o",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2023-05-15",
            "deployment_name": "text-embedding-3-small",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output\\lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
14:03:22,758 graphrag.storage.file_pipeline_storage INFO Creating file storage at C:\Users\ccoello\Documents\GraphRag\ragtest\output
14:03:22,759 graphrag.index.input.factory INFO loading input from root_dir=input
14:03:22,759 graphrag.index.input.factory INFO using file storage for input
14:03:22,760 graphrag.storage.file_pipeline_storage INFO search C:\Users\ccoello\Documents\GraphRag\ragtest\input for files matching .*\.txt$
14:03:22,764 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
14:03:22,764 graphrag.index.input.util INFO Total number of unfiltered text rows: 1
14:03:22,767 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
14:03:22,785 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:03:22,881 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:03:22,884 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:22,936 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:03:30,698 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:36,181 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:36,791 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:37,578 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:37,596 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:37,623 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:37,624 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:03:37,642 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:37,643 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:03:37,997 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:38,46 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:38,46 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:03:38,960 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:39,37 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:39,38 openai._base_client INFO Retrying request to /chat/completions in 45.000000 seconds
14:03:39,406 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:39,460 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:39,460 openai._base_client INFO Retrying request to /chat/completions in 44.000000 seconds
14:03:40,263 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:40,307 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:40,308 openai._base_client INFO Retrying request to /chat/completions in 43.000000 seconds
14:03:40,589 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:40,646 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:40,647 openai._base_client INFO Retrying request to /chat/completions in 43.000000 seconds
14:03:40,671 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:40,744 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:40,744 openai._base_client INFO Retrying request to /chat/completions in 43.000000 seconds
14:03:41,360 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:41,409 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:41,411 openai._base_client INFO Retrying request to /chat/completions in 42.000000 seconds
14:03:42,387 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:42,436 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:42,437 openai._base_client INFO Retrying request to /chat/completions in 41.000000 seconds
14:03:42,447 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:42,493 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:42,495 openai._base_client INFO Retrying request to /chat/completions in 41.000000 seconds
14:03:43,237 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:43,267 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:43,283 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:43,284 openai._base_client INFO Retrying request to /chat/completions in 40.000000 seconds
14:03:43,314 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:43,315 openai._base_client INFO Retrying request to /chat/completions in 40.000000 seconds
14:03:44,65 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:44,113 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:44,114 openai._base_client INFO Retrying request to /chat/completions in 40.000000 seconds
14:03:44,284 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:44,336 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:44,337 openai._base_client INFO Retrying request to /chat/completions in 39.000000 seconds
14:03:44,500 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:44,549 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:44,550 openai._base_client INFO Retrying request to /chat/completions in 39.000000 seconds
14:03:45,370 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:45,418 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:45,419 openai._base_client INFO Retrying request to /chat/completions in 38.000000 seconds
14:03:45,559 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:45,610 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:45,612 openai._base_client INFO Retrying request to /chat/completions in 38.000000 seconds
14:03:46,70 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:46,119 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:46,119 openai._base_client INFO Retrying request to /chat/completions in 38.000000 seconds
14:03:46,248 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:46,304 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:46,305 openai._base_client INFO Retrying request to /chat/completions in 37.000000 seconds
14:03:47,270 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:47,321 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:47,322 openai._base_client INFO Retrying request to /chat/completions in 36.000000 seconds
14:03:47,836 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:47,886 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:47,886 openai._base_client INFO Retrying request to /chat/completions in 36.000000 seconds
14:03:48,14 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:48,64 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:48,64 openai._base_client INFO Retrying request to /chat/completions in 36.000000 seconds
14:03:48,582 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:48,638 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:48,640 openai._base_client INFO Retrying request to /chat/completions in 35.000000 seconds
14:03:49,651 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:03:49,697 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:03:49,697 openai._base_client INFO Retrying request to /chat/completions in 34.000000 seconds
14:04:23,658 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,658 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,694 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,694 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,694 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,694 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,788 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,794 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,797 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,798 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,807 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,808 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,835 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,836 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,839 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,840 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,844 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,844 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,859 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,859 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:23,959 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:23,959 openai._base_client INFO Retrying request to /chat/completions in 8.000000 seconds
14:04:24,93 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:24,93 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:04:24,93 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:24,93 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:04:24,123 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:24,127 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:04:24,165 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:24,166 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:04:24,169 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:24,170 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:04:27,323 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:27,377 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:27,377 openai._base_client INFO Retrying request to /chat/completions in 4.000000 seconds
14:04:27,492 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:27,545 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:27,545 openai._base_client INFO Retrying request to /chat/completions in 4.000000 seconds
14:04:28,502 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:28,553 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:28,554 openai._base_client INFO Retrying request to /chat/completions in 3.000000 seconds
14:04:30,134 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:30,189 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:30,190 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:04:30,230 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:30,279 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:30,281 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:04:30,876 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:30,929 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:30,929 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:04:30,962 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:31,7 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:31,8 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:04:32,4 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:32,5 openai._base_client INFO Retrying request to /chat/completions in 5.000000 seconds
14:04:32,75 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:32,76 openai._base_client INFO Retrying request to /chat/completions in 52.000000 seconds
14:04:32,117 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:32,118 openai._base_client INFO Retrying request to /chat/completions in 52.000000 seconds
14:04:32,140 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:32,140 openai._base_client INFO Retrying request to /chat/completions in 52.000000 seconds
14:04:34,947 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:35,1 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:35,2 openai._base_client INFO Retrying request to /chat/completions in 49.000000 seconds
14:04:37,44 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:37,44 openai._base_client INFO Retrying request to /chat/completions in 47.000000 seconds
14:04:37,296 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:37,347 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:37,347 openai._base_client INFO Retrying request to /chat/completions in 47.000000 seconds
14:04:37,388 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:37,435 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:37,436 openai._base_client INFO Retrying request to /chat/completions in 47.000000 seconds
14:04:37,542 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:37,592 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:37,592 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:04:37,732 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:37,759 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:37,784 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:37,784 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:04:37,812 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:37,812 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:04:38,146 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:38,198 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:38,198 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:04:38,392 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:38,439 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:38,440 openai._base_client INFO Retrying request to /chat/completions in 46.000000 seconds
14:04:38,506 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:38,664 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:38,722 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:38,723 openai._base_client INFO Retrying request to /chat/completions in 45.000000 seconds
14:04:39,428 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:39,512 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:40,290 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:40,442 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:40,488 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:40,489 openai._base_client INFO Retrying request to /chat/completions in 44.000000 seconds
14:04:41,430 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:41,477 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:41,477 openai._base_client INFO Retrying request to /chat/completions in 43.000000 seconds
14:04:42,206 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:42,261 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:42,261 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:42,261 openai._base_client INFO Retrying request to /chat/completions in 42.000000 seconds
14:04:42,542 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:43,541 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:43,544 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:43,594 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:43,595 openai._base_client INFO Retrying request to /chat/completions in 40.000000 seconds
14:04:43,600 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:43,601 openai._base_client INFO Retrying request to /chat/completions in 40.000000 seconds
14:04:44,307 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:04:44,358 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:04:44,359 openai._base_client INFO Retrying request to /chat/completions in 40.000000 seconds
14:05:24,197 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,198 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,264 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,264 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,267 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,268 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,295 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,295 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,345 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,345 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,376 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,376 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,411 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,412 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,495 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,495 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,497 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,497 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,501 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,501 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:24,558 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:24,558 openai._base_client INFO Retrying request to /chat/completions in 7.000000 seconds
14:05:26,827 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:27,510 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:28,277 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:28,326 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:28,326 openai._base_client INFO Retrying request to /chat/completions in 3.000000 seconds
14:05:29,749 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:29,803 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:29,803 openai._base_client INFO Retrying request to /chat/completions in 2.000000 seconds
14:05:30,446 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:30,490 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:30,490 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:31,278 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:31,492 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:31,493 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:31,529 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:31,529 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:31,557 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:31,564 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:31,564 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:31,564 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:31,604 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:31,605 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:31,645 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:31,646 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:31,683 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:31,684 openai._base_client INFO Retrying request to /chat/completions in 1.000000 seconds
14:05:34,190 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:34,971 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:36,339 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:36,755 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:36,815 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:37,142 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:37,734 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:38,501 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:39,921 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:40,140 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:40,344 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:41,535 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:41,590 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:41,591 openai._base_client INFO Retrying request to /chat/completions in 43.000000 seconds
14:05:41,740 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:42,707 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:42,892 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:42,938 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:42,939 openai._base_client INFO Retrying request to /chat/completions in 41.000000 seconds
14:05:43,224 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:43,275 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:05:43,276 openai._base_client INFO Retrying request to /chat/completions in 41.000000 seconds
14:05:44,714 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:47,645 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:05:49,51 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:28,589 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:29,354 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:31,838 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:34,261 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:35,671 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,136 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,194 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,338 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,342 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,452 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,536 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,604 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,620 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,620 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,685 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,738 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,766 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,823 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,823 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:36,959 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:37,456 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:37,561 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:37,793 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,70 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,133 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,220 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,312 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,391 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,403 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,487 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,504 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,536 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,650 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,694 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,782 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,803 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,863 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:38,971 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:39,367 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:39,620 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:39,963 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:39,966 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:40,319 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:40,420 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:40,603 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:40,771 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:40,851 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:40,871 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:41,258 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:41,517 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:42,940 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,56 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,420 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,556 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,605 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,704 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,721 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,857 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,883 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,904 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,921 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:43,956 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:44,83 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:44,607 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:44,616 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:44,624 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:44,904 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:45,292 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:45,295 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:45,486 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:45,527 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:45,570 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:45,625 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:45,771 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,3 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,26 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,41 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,112 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,166 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,168 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,255 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,356 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,878 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:46,912 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,16 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,37 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,139 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,480 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,526 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,709 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,711 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:47,884 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:48,244 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:48,403 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:49,29 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:49,306 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:51,437 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:06:51,504 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:06:51,522 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:06:51,624 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:06:51,642 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:06:51,804 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:06:51,824 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:06:51,824 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:06:51,923 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:06:51,927 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:06:51,931 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:06:51,981 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=2 => 60
14:06:52,107 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=1 => 226
14:06:52,478 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 230
14:06:53,236 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:06:53,236 openai._base_client INFO Retrying request to /chat/completions in 32.000000 seconds
14:07:40,115 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:07:49,967 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:07:50,564 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:07:52,252 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:07:52,841 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:07:55,466 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:07:56,130 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:04,329 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:13,78 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:13,133 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:13,133 openai._base_client INFO Retrying request to /chat/completions in 28.000000 seconds
14:08:15,291 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:15,333 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:15,333 openai._base_client INFO Retrying request to /chat/completions in 26.000000 seconds
14:08:15,470 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:15,527 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:15,527 openai._base_client INFO Retrying request to /chat/completions in 25.000000 seconds
14:08:15,850 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:15,917 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:15,919 openai._base_client INFO Retrying request to /chat/completions in 25.000000 seconds
14:08:16,1 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:16,50 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:16,50 openai._base_client INFO Retrying request to /chat/completions in 25.000000 seconds
14:08:16,763 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:16,849 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:16,850 openai._base_client INFO Retrying request to /chat/completions in 24.000000 seconds
14:08:17,47 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:17,101 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:17,102 openai._base_client INFO Retrying request to /chat/completions in 24.000000 seconds
14:08:18,402 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:18,449 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:18,449 openai._base_client INFO Retrying request to /chat/completions in 22.000000 seconds
14:08:18,697 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:18,752 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:18,753 openai._base_client INFO Retrying request to /chat/completions in 22.000000 seconds
14:08:19,401 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:20,816 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:21,511 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:21,710 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:21,934 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:22,24 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:23,36 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:23,983 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:24,117 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:24,271 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:24,401 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:24,453 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:29,86 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:29,586 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:35,50 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:35,266 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:41,81 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:41,81 openai._base_client INFO Retrying request to /chat/completions in 24.000000 seconds
14:08:41,182 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:41,182 openai._base_client INFO Retrying request to /chat/completions in 24.000000 seconds
14:08:41,223 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:41,224 openai._base_client INFO Retrying request to /chat/completions in 24.000000 seconds
14:08:41,229 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:41,229 openai._base_client INFO Retrying request to /chat/completions in 24.000000 seconds
14:08:41,368 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 429 Too Many Requests"
14:08:41,369 openai._base_client INFO Retrying request to /chat/completions in 24.000000 seconds
14:08:48,965 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:53,382 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:54,242 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:08:56,413 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:16,180 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:16,814 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:21,497 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:25,408 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:30,694 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:45,579 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:49,129 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:50,613 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:50,709 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:51,503 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:54,153 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:57,298 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:58,399 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:09:58,536 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:09:58,565 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:09:58,569 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:09:58,579 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:09:58,579 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:09:58,611 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:09:58,611 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:09:58,648 graphrag.index.operations.embed_text.strategies.openai INFO embedding 287 inputs via 287 snippets using 18 batches. max_batch_size=16, batch_max_tokens=8191
14:09:59,63 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:10:59,35 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:11:59,19 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:12:59,56 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:13:46,572 graphrag.cli.index INFO Logging enabled at C:\Users\ccoello\Documents\GraphRag\ragtest\logs\indexing-engine.log
14:13:47,819 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:48,193 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:13:48,196 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:13:48,196 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "encoding_model": "o200k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2025-01-01-preview",
            "deployment_name": "gpt-4o",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2023-05-15",
            "deployment_name": "text-embedding-3-small",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output\\lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
14:13:48,198 graphrag.storage.file_pipeline_storage INFO Creating file storage at C:\Users\ccoello\Documents\GraphRag\ragtest\output
14:13:48,198 graphrag.index.input.factory INFO loading input from root_dir=input
14:13:48,198 graphrag.index.input.factory INFO using file storage for input
14:13:48,199 graphrag.storage.file_pipeline_storage INFO search C:\Users\ccoello\Documents\GraphRag\ragtest\input for files matching .*\.txt$
14:13:48,246 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
14:13:48,247 graphrag.index.input.util INFO Total number of unfiltered text rows: 1
14:13:48,249 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
14:13:48,267 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:13:48,366 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:13:48,370 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:13:48,423 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:13:49,314 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,5 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,16 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,17 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,18 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,19 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,65 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,78 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,85 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,85 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,137 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,171 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,171 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,269 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,272 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,274 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,302 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,302 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,391 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,402 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,404 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,404 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,407 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,416 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:50,417 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:51,795 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:53,251 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:53,997 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,8 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,43 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,368 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,414 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,454 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,458 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,582 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:54,919 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:55,736 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:57,848 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:13:59,93 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:14:00,18 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:01,833 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:02,236 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:02,356 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:02,534 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:02,667 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:02,758 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:02,814 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:02,876 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:14:02,885 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:14:02,974 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:14:02,997 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:14:03,119 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:14:03,119 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:14:03,119 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:14:03,217 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:14:03,218 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:14:03,218 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:14:03,250 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=2 => 36
14:14:03,333 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=1 => 117
14:14:03,519 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 135
14:14:26,984 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:39,693 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:49,837 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:49,977 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:50,203 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:50,213 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:50,758 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:50,803 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:50,851 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:50,927 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:51,375 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:51,533 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:52,426 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:52,634 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:53,39 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:55,349 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:55,540 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:55,808 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:56,733 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:14:59,33 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:14:59,383 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:02,473 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:14,150 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:18,473 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:21,501 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:21,565 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:27,414 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:28,605 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:28,959 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:15:29,62 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:15:29,87 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:15:29,92 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:15:29,114 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:15:29,116 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:15:29,145 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:15:29,145 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:15:29,181 graphrag.index.operations.embed_text.strategies.openai INFO embedding 166 inputs via 166 snippets using 11 batches. max_batch_size=16, batch_max_tokens=8191
14:15:29,511 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:15:59,34 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:16:29,530 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:16:59,55 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:17:29,577 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:17:59,95 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:18:29,533 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:18:59,40 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:19:29,544 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:19:59,57 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:20:29,618 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:20:53,452 graphrag.cli.index INFO Logging enabled at C:\Users\ccoello\Documents\GraphRag\ragtest\logs\indexing-engine.log
14:20:54,767 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:20:55,268 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:20:55,272 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:20:55,272 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "encoding_model": "o200k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2025-01-01-preview",
            "deployment_name": "gpt-4o",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2023-05-15",
            "deployment_name": "text-embedding-3-small",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output\\lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
14:20:55,273 graphrag.storage.file_pipeline_storage INFO Creating file storage at C:\Users\ccoello\Documents\GraphRag\ragtest\output
14:20:55,274 graphrag.index.input.factory INFO loading input from root_dir=input
14:20:55,274 graphrag.index.input.factory INFO using file storage for input
14:20:55,275 graphrag.storage.file_pipeline_storage INFO search C:\Users\ccoello\Documents\GraphRag\ragtest\input for files matching .*\.txt$
14:20:59,53 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:21:29,564 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:21:59,93 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:22:29,574 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:22:59,157 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:23:20,959 graphrag.cli.index INFO Logging enabled at C:\Users\ccoello\Documents\GraphRag\ragtest\logs\indexing-engine.log
14:23:22,95 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:23:22,463 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:23:22,467 graphrag.cli.index INFO Starting pipeline run. dry_run=False
14:23:22,468 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "encoding_model": "o200k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2025-01-01-preview",
            "deployment_name": "gpt-4o",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2023-05-15",
            "deployment_name": "text-embedding-3-small",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output\\lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
14:23:22,469 graphrag.storage.file_pipeline_storage INFO Creating file storage at C:\Users\ccoello\Documents\GraphRag\ragtest\output
14:23:22,469 graphrag.index.input.factory INFO loading input from root_dir=input
14:23:22,469 graphrag.index.input.factory INFO using file storage for input
14:23:22,470 graphrag.storage.file_pipeline_storage INFO search C:\Users\ccoello\Documents\GraphRag\ragtest\input for files matching .*\.txt$
14:23:22,473 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
14:23:22,474 graphrag.index.input.util INFO Total number of unfiltered text rows: 1
14:23:22,476 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
14:23:22,486 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:23:22,537 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:23:22,543 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:23:22,595 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:23:29,640 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:23:32,344 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:23:48,780 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:23:48,858 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:23:48,883 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:23:48,943 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:23:48,965 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:23:49,40 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:23:49,43 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:23:49,47 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:23:49,96 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:23:49,96 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:23:49,96 graphrag.utils.storage INFO reading table from storage: communities.parquet
14:23:49,143 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 17
14:23:59,141 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:24:06,443 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
14:24:06,531 graphrag.utils.storage INFO reading table from storage: documents.parquet
14:24:06,560 graphrag.utils.storage INFO reading table from storage: relationships.parquet
14:24:06,564 graphrag.utils.storage INFO reading table from storage: text_units.parquet
14:24:06,576 graphrag.utils.storage INFO reading table from storage: entities.parquet
14:24:06,576 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
14:24:06,603 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
14:24:06,603 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
14:24:06,610 graphrag.index.operations.embed_text.strategies.openai INFO embedding 17 inputs via 17 snippets using 2 batches. max_batch_size=16, batch_max_tokens=8191
14:24:06,927 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:24:29,575 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:24:59,109 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:25:06,809 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:25:07,54 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:25:07,57 graphrag.index.operations.embed_text.strategies.openai INFO embedding 1 inputs via 1 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
14:25:29,555 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:25:29,919 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:25:29,940 graphrag.index.operations.embed_text.strategies.openai INFO embedding 28 inputs via 28 snippets using 4 batches. max_batch_size=16, batch_max_tokens=8191
14:25:59,244 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:26:06,855 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:26:06,895 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:26:06,898 graphrag.index.operations.embed_text.strategies.openai INFO embedding 1 inputs via 1 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
14:26:29,658 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:26:59,122 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:26:59,490 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
14:26:59,538 graphrag.index.operations.embed_text.strategies.openai INFO embedding 50 inputs via 50 snippets using 6 batches. max_batch_size=16, batch_max_tokens=8191
14:27:06,902 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:27:07,21 graphrag.cli.index INFO All workflows completed successfully.
14:27:29,735 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:27:59,191 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:28:29,695 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:28:59,328 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:29:29,640 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:29:29,679 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:29:29,729 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 7 batches. max_batch_size=16, batch_max_tokens=8191
14:29:59,261 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:30:29,708 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:30:59,324 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:31:29,721 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:31:59,339 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:32:29,707 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:32:59,288 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:32:59,361 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
14:32:59,402 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 7 batches. max_batch_size=16, batch_max_tokens=8191
14:33:29,737 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:33:59,263 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:34:29,717 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:34:59,254 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:35:29,768 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:35:59,304 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:36:29,802 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:36:30,38 graphrag.cli.index INFO All workflows completed successfully.
14:36:59,336 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
14:36:59,608 graphrag.cli.index INFO All workflows completed successfully.
15:13:54,942 graphrag.cli.index INFO Logging enabled at C:\Users\ccoello\Documents\GraphRag\ragtest\logs\indexing-engine.log
15:13:56,51 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
15:13:56,442 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
15:13:56,442 graphrag.cli.index INFO Starting pipeline run. dry_run=False
15:13:56,442 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_chat",
            "model": "gpt-4o",
            "encoding_model": "o200k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2025-01-01-preview",
            "deployment_name": "gpt-4o",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "azure_openai_embedding",
            "model": "text-embedding-3-small",
            "encoding_model": "cl100k_base",
            "api_base": "https://aoaigraphrag01.openai.azure.com",
            "api_version": "2023-05-15",
            "deployment_name": "text-embedding-3-small",
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": "auto",
            "requests_per_minute": "auto",
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "C:\\Users\\ccoello\\Documents\\GraphRag\\ragtest\\output\\lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
15:13:56,442 graphrag.storage.file_pipeline_storage INFO Creating file storage at C:\Users\ccoello\Documents\GraphRag\ragtest\output
15:13:56,442 graphrag.index.input.factory INFO loading input from root_dir=input
15:13:56,442 graphrag.index.input.factory INFO using file storage for input
15:13:56,442 graphrag.storage.file_pipeline_storage INFO search C:\Users\ccoello\Documents\GraphRag\ragtest\input for files matching .*\.txt$
15:13:56,459 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
15:13:56,459 graphrag.index.input.util INFO Total number of unfiltered text rows: 1
15:13:56,474 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
15:13:56,477 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:13:56,533 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:13:56,536 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:13:56,575 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:13:56,724 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:13:56,742 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:13:56,792 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:13:56,808 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:13:56,900 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:13:56,902 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:13:56,906 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:13:56,969 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:13:56,969 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:13:56,975 graphrag.utils.storage INFO reading table from storage: communities.parquet
15:13:57,24 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 9
15:14:14,658 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2025-01-01-preview "HTTP/1.1 200 OK"
15:14:14,730 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:14:14,751 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:14:14,754 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:14:14,774 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:14:14,774 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
15:14:14,796 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
15:14:14,797 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
15:14:15,16 graphrag.index.operations.embed_text.strategies.openai INFO embedding 9 inputs via 9 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
15:14:15,507 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
15:14:15,601 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
15:14:15,605 graphrag.index.operations.embed_text.strategies.openai INFO embedding 1 inputs via 1 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
15:15:15,271 httpx INFO HTTP Request: POST https://aoaigraphrag01.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15 "HTTP/1.1 200 OK"
15:15:15,322 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
15:15:15,322 graphrag.index.operations.embed_text.strategies.openai INFO embedding 1 inputs via 1 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
15:15:15,422 graphrag.cli.index INFO All workflows completed successfully.
